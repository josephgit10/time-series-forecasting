{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bb8c7",
   "metadata": {},
   "source": [
    "Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/processed/merged_data.csv', parse_dates=['Date'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'merged_data.csv' not found. Please run the preprocessing script first.\")\n",
    "    df = None \n",
    "\n",
    "if df is not None:\n",
    "    store_df = df[df['Store'] == 1].copy()\n",
    "\n",
    "    store_df.sort_values('Date', inplace=True)\n",
    "    \n",
    "    print(f\"Data loaded for Store 1. Shape: {store_df.shape}\")\n",
    "    display(store_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ae76a",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Time-based features\n",
    "    store_df['Year'] = store_df['Date'].dt.year\n",
    "    store_df['Month'] = store_df['Date'].dt.month\n",
    "    store_df['WeekOfYear'] = store_df['Date'].dt.isocalendar().week.astype(int)\n",
    "    store_df['DayOfYear'] = store_df['Date'].dt.dayofyear\n",
    "    \n",
    "    # Lag features (past sales values)\n",
    "    store_df['Lag_1'] = store_df['Weekly_Sales'].shift(1) # Sales from last week\n",
    "    store_df['Lag_4'] = store_df['Weekly_Sales'].shift(4) # Sales from a month ago\n",
    "    store_df['Lag_52'] = store_df['Weekly_Sales'].shift(52) # Sales from a year ago\n",
    "\n",
    "    # Rolling window features\n",
    "    store_df['Rolling_Mean_4'] = store_df['Weekly_Sales'].shift(1).rolling(window=4).mean()\n",
    "    store_df['Rolling_Std_4'] = store_df['Weekly_Sales'].shift(1).rolling(window=4).std()\n",
    "\n",
    "    store_df.dropna(inplace=True)\n",
    "    \n",
    "    print(\"Features created. Shape after dropping NaNs:\", store_df.shape)\n",
    "    display(store_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0205d",
   "metadata": {},
   "source": [
    "Define Features and Target & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Define feature columns and the target column\n",
    "    FEATURES = [\n",
    "        'Year', 'Month', 'WeekOfYear', 'DayOfYear', # Time features\n",
    "        'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', # External features\n",
    "        'Lag_1', 'Lag_4', 'Lag_52', # Lag features\n",
    "        'Rolling_Mean_4', 'Rolling_Std_4' # Rolling window features\n",
    "    ]\n",
    "    TARGET = 'Weekly_Sales'\n",
    "\n",
    "    X = store_df[FEATURES]\n",
    "    y = store_df[TARGET]\n",
    "\n",
    "    train_size = int(len(X) * 0.7)\n",
    "    val_size = int(len(X) * 0.15)\n",
    "    \n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "    X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3a7cd",
   "metadata": {},
   "source": [
    "Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c32d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 2000, step=100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "        # Initialize and train the XGBoost model\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  early_stopping_rounds=50, \n",
    "                  verbose=False)\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        return rmse\n",
    "\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "    print(\"\\n--- OPTIMIZATION FINISHED ---\")\n",
    "    print(f\"Number of finished trials: {len(study.trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994e91e",
   "metadata": {},
   "source": [
    "Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f87378",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print('Best trial found:')\n",
    "    best_trial = study.best_trial\n",
    "    print(f'  Value (Validation RMSE): {best_trial.value:,.2f}')\n",
    "    print('  Best Params: ')\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f'    {key}: {value}')\n",
    "        \n",
    "    \n",
    "    print(\"\\n--- Evaluating final model on test set ---\")\n",
    "    final_model = xgb.XGBRegressor(**best_trial.params)\n",
    "    \n",
    "    # Combine train and validation data to train the final model\n",
    "    X_train_full = pd.concat([X_train, X_val])\n",
    "    y_train_full = pd.concat([y_train, y_val])\n",
    "    \n",
    "    final_model.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    test_preds = final_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    \n",
    "    print(f\"Final Model RMSE on unseen Test Data: {test_rmse:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
